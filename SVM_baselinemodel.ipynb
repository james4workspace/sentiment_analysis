{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import sklearn\n",
    "from tqdm import tqdm\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_name={\n",
    "    \"y_train\":\"train_y\",\n",
    "    \"y_test\":\"test_y\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_pkl(file_name):\n",
    "    all_data=dict()\n",
    "    for each_key in file_name.keys():\n",
    "        name = file_name[each_key]\n",
    "        pickle_file = open('DataSet\\\\'+name+\".pkl\",mode=\"rb\")\n",
    "        data = pickle.load(pickle_file)\n",
    "        pickle_file.close()\n",
    "        all_data[each_key]=data\n",
    "    return all_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_data = open_pkl(y_name)\n",
    "y_train = y_data[\"y_train\"]\n",
    "y_test = y_data[\"y_test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 3, 0, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = \"DataSet\\\\train_df_tfidf.csv\"\n",
    "train_df = pd.read_csv(train_path,sep=\",\")\n",
    "\n",
    "test_path = \"DataSet\\\\test_df_tfidf.csv\"\n",
    "test_df = pd.read_csv(test_path,sep=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ur</th>\n",
       "      <th>name</th>\n",
       "      <th>how</th>\n",
       "      <th>know</th>\n",
       "      <th>you</th>\n",
       "      <th>not</th>\n",
       "      <th>hmm</th>\n",
       "      <th>are</th>\n",
       "      <th>what</th>\n",
       "      <th>do</th>\n",
       "      <th>...</th>\n",
       "      <th>heheheheh</th>\n",
       "      <th>roadsid</th>\n",
       "      <th>chiranjeevi</th>\n",
       "      <th>pawankalyan</th>\n",
       "      <th>drone</th>\n",
       "      <th>salaman</th>\n",
       "      <th>conphyooj</th>\n",
       "      <th>grasshopp</th>\n",
       "      <th>freeeeeeeeeeeeee</th>\n",
       "      <th>dilut</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.077528</td>\n",
       "      <td>3.860727</td>\n",
       "      <td>0.679187</td>\n",
       "      <td>0.66649</td>\n",
       "      <td>0.116415</td>\n",
       "      <td>0.213284</td>\n",
       "      <td>6.469326</td>\n",
       "      <td>0.31208</td>\n",
       "      <td>0.266851</td>\n",
       "      <td>0.289638</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.161189</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.299352</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.212219</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.434457</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 8399 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         ur      name       how     know       you       not       hmm  \\\n",
       "0  1.077528  3.860727  0.679187  0.66649  0.116415  0.213284  6.469326   \n",
       "1  0.000000  0.000000  0.000000  0.00000  0.161189  0.000000  0.000000   \n",
       "2  0.000000  0.000000  0.000000  0.00000  0.299352  0.000000  0.000000   \n",
       "3  1.212219  0.000000  0.000000  0.00000  0.000000  0.000000  0.000000   \n",
       "4  0.000000  0.000000  0.000000  0.00000  0.000000  0.000000  0.000000   \n",
       "\n",
       "       are      what        do  ...  heheheheh  roadsid  chiranjeevi  \\\n",
       "0  0.31208  0.266851  0.289638  ...        0.0      0.0          0.0   \n",
       "1  0.00000  0.000000  0.000000  ...        0.0      0.0          0.0   \n",
       "2  0.00000  0.000000  0.000000  ...        0.0      0.0          0.0   \n",
       "3  0.00000  0.000000  0.000000  ...        0.0      0.0          0.0   \n",
       "4  0.00000  0.000000  0.434457  ...        0.0      0.0          0.0   \n",
       "\n",
       "   pawankalyan  drone  salaman  conphyooj  grasshopp  freeeeeeeeeeeeee  dilut  \n",
       "0          0.0    0.0      0.0        0.0        0.0               0.0    0.0  \n",
       "1          0.0    0.0      0.0        0.0        0.0               0.0    0.0  \n",
       "2          0.0    0.0      0.0        0.0        0.0               0.0    0.0  \n",
       "3          0.0    0.0      0.0        0.0        0.0               0.0    0.0  \n",
       "4          0.0    0.0      0.0        0.0        0.0               0.0    0.0  \n",
       "\n",
       "[5 rows x 8399 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ur</th>\n",
       "      <th>name</th>\n",
       "      <th>how</th>\n",
       "      <th>know</th>\n",
       "      <th>you</th>\n",
       "      <th>not</th>\n",
       "      <th>hmm</th>\n",
       "      <th>are</th>\n",
       "      <th>what</th>\n",
       "      <th>do</th>\n",
       "      <th>...</th>\n",
       "      <th>heheheheh</th>\n",
       "      <th>roadsid</th>\n",
       "      <th>chiranjeevi</th>\n",
       "      <th>pawankalyan</th>\n",
       "      <th>drone</th>\n",
       "      <th>salaman</th>\n",
       "      <th>conphyooj</th>\n",
       "      <th>grasshopp</th>\n",
       "      <th>freeeeeeeeeeeeee</th>\n",
       "      <th>dilut</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.586171</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.436665</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.299352</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.686188</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.528172</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.299352</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.686188</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.209546</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.480331</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 8399 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    ur  name       how  know       you  not        hmm  are      what   do  \\\n",
       "0  0.0   0.0  0.000000   0.0  0.000000  0.0  10.586171  0.0  0.436665  0.0   \n",
       "1  0.0   0.0  0.000000   0.0  0.299352  0.0   0.000000  0.0  0.686188  0.0   \n",
       "2  0.0   0.0  1.528172   0.0  0.000000  0.0   0.000000  0.0  0.000000  0.0   \n",
       "3  0.0   0.0  0.000000   0.0  0.299352  0.0   0.000000  0.0  0.686188  0.0   \n",
       "4  0.0   0.0  0.000000   0.0  0.209546  0.0   0.000000  0.0  0.480331  0.0   \n",
       "\n",
       "   ...  heheheheh  roadsid  chiranjeevi  pawankalyan  drone  salaman  \\\n",
       "0  ...        0.0      0.0          0.0          0.0    0.0      0.0   \n",
       "1  ...        0.0      0.0          0.0          0.0    0.0      0.0   \n",
       "2  ...        0.0      0.0          0.0          0.0    0.0      0.0   \n",
       "3  ...        0.0      0.0          0.0          0.0    0.0      0.0   \n",
       "4  ...        0.0      0.0          0.0          0.0    0.0      0.0   \n",
       "\n",
       "   conphyooj  grasshopp  freeeeeeeeeeeeee  dilut  \n",
       "0        0.0        0.0               0.0    0.0  \n",
       "1        0.0        0.0               0.0    0.0  \n",
       "2        0.0        0.0               0.0    0.0  \n",
       "3        0.0        0.0               0.0    0.0  \n",
       "4        0.0        0.0               0.0    0.0  \n",
       "\n",
       "[5 rows x 8399 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_np = train_df.iloc[:, :].values\n",
    "test_np = test_df.iloc[:,:].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in case I have more versions of dataset for better model building\n",
    "X_train = dict()\n",
    "X_test = dict()\n",
    "\n",
    "X_train[\"train_baseline\"]=train_np\n",
    "X_test[\"test_baseline\"]=test_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 1.52817187, ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       ...,\n",
       "       [0.        , 0.        , 1.22253749, ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test[\"test_baseline\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.SVM Model\n",
    "## 2.1. build and fit model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "def svm_model(train_data,y_train):\n",
    "    classifiers = dict()\n",
    "    for key in tqdm(train_data.keys()):\n",
    "        classifier = SVC(kernel = 'linear', random_state=0)\n",
    "        classifier.fit(train_data[key],y_train)\n",
    "        classifiers[key]=classifier\n",
    "    \n",
    "    return classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                            | 0/1 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "classifiers = svm_model(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model\n",
    "def save_data(name,data):\n",
    "    pickle_file = open('DataSet\\\\'+name+\".pkl\",mode='wb')\n",
    "    pickle.dump(data,pickle_file)\n",
    "    pickle_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model\n",
    "save_data(\"SVM_baseline\",classifiers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2. prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for getting prediction\n",
    "def get_prediction(classifiers, X_test):\n",
    "    y_pred_dict= dict()\n",
    "    list1 = list(classifiers.keys())\n",
    "    list2 = list(X_test.keys())\n",
    "    length = len(list1)\n",
    "    \n",
    "    for i in tqdm(range(length)):\n",
    "        y_pred_dict[list2[i]]=classifiers[list1[i]].predict(X_test[list2[i]])\n",
    "        \n",
    "    return y_pred_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preds = get_prediction(classifiers,X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for getting the score of each prediction\n",
    "def get_scores(classifiers, X_test):\n",
    "    y_score_dict= dict()\n",
    "    list1 = list(classifiers.keys())\n",
    "    list2 = list(X_test.keys())\n",
    "    length = len(list1)\n",
    "    \n",
    "    for i in tqdm(range(length)):\n",
    "        y_score_dict[list2[i]]=classifiers[list1[i]].decision_function(X_test[list2[i]])\n",
    "        \n",
    "    return y_score_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_scores = get_scores(classifiers, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for saving the predictions and scores\n",
    "def save_prediction(name,data):\n",
    "    pickle_file = open('Prediction\\\\'+name+\".pkl\",mode='wb')\n",
    "    pickle.dump(data,pickle_file)\n",
    "    pickle_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_prediction(\"baseline_svm_preds\",y_preds)\n",
    "save_prediction(\"baseline_svm_scores\",y_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3. Evaluation: confusion matrix, accuracy, precision, recall, F1 measure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "# print evaluation result\n",
    "def get_evaluation(y_test,y_pred):\n",
    "    ev = dict()\n",
    "    ev[\"confusion_matrix\"]=confusion_matrix(y_test,y_pred)\n",
    "    ev[\"accuracy\"] = accuracy_score(y_test,y_pred)\n",
    "    ev[\"precision_macro\"]=precision_score(y_test,y_pred,average=\"macro\")\n",
    "    ev[\"precision_micro\"]=precision_score(y_test,y_pred,average=\"micro\")\n",
    "    ev[\"precision_weighted\"]=precision_score(y_test,y_pred,average=\"weighted\")\n",
    "    ev[\"recall_macro\"]=recall_score(y_test,y_pred,average=\"macro\")\n",
    "    ev[\"recall_micro\"]=recall_score(y_test,y_pred,average=\"micro\")\n",
    "    ev[\"recall_weighted\"]=recall_score(y_test,y_pred,average=\"weighted\")\n",
    "    ev[\"F1_score_macro\"]=f1_score(y_test,y_pred,average=\"macro\")\n",
    "    ev[\"F1_score_micro\"]=f1_score(y_test,y_pred,average=\"micro\")\n",
    "    ev[\"F1_score_weighted\"]=f1_score(y_test,y_pred,average=\"weighted\")\n",
    "    \n",
    "    for key in ev.keys():\n",
    "        if key !=\"confusion_matrix\":\n",
    "            print(\"{a} is: {b}\".format(a=key, b=ev[key]))\n",
    "        else:\n",
    "            print(ev[key])\n",
    "    \n",
    "    return ev\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\"macro\": \"Calculate metrics for each label, and find their unweighted mean. \",\n",
    "#\"micro\": \"Calculate metrics globally by counting the total true positives, false negatives and false positives.\"\n",
    "#\"weighted\":\"Calculate metrics for each label, and find their average weighted by support (the number of true instances for each label). \"\n",
    "\n",
    "def get_evaluation_all(y_test, y_pred_dict):\n",
    "    for key in tqdm(y_pred_dict.keys()):\n",
    "        print(\"evaluation on data {0}\".format(key))\n",
    "        get_evaluation(y_test, y_pred_dict[key])\n",
    "        print(\"***************************************\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_evaluation_all(y_test,y_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4. Evaluation: ROC curve, AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in order to plot ROC curve and calculate AUC, I need to turn y label into 1 hot representation.\n",
    "# transfer y label from {class:[0,1,2,3]} into {class: [1,0,0,0], [0,1,0,0],[0,0,1,0],[0,0,0,1]}\n",
    "import tensorflow as tf\n",
    "y_test1hot = tf.keras.utils.to_categorical(y_test,num_classes=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emotion = {\"others\":0,\"happy\":1,\"sad\":2,\"angry\":3}\n",
    "print(y_test1hot[13])#3 - 4th\n",
    "print(y_test1hot[0])#0 - 1st\n",
    "print(y_test1hot[6])#1 - 2nd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve,auc\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import average_precision_score\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_roc_auc(y_test1hot, y_score):\n",
    "    fpr = dict()\n",
    "    tpr = dict()\n",
    "    roc_auc = dict()\n",
    "    n_class = 4\n",
    "    \n",
    "    # compute roc curve and auc based on each label\n",
    "    for i in range(n_class):\n",
    "        fpr[i],tpr[i],_ = roc_curve(y_test1hot[:,i],y_score[:,i])\n",
    "        roc_auc[i] = auc(fpr[i],tpr[i])\n",
    "    \n",
    "    # compute roc curve and auc based on average type = \"micro\"\n",
    "    fpr[\"micro\"],tpr[\"micro\"],_=roc_curve(y_test1hot.ravel(),y_score.ravel())\n",
    "    roc_auc[\"micro\"]=auc(fpr[\"micro\"],tpr[\"micro\"])\n",
    "    \n",
    "    # compute roc curve and auc based on average type = \"macro\"\n",
    "    # First aggregate all false positive rates\n",
    "    all_fpr = np.unique(np.concatenate([fpr[i] for i in range(n_class)]))\n",
    "    # Then interpolate all ROC curves at this points\n",
    "    mean_tpr = np.zeros_like(all_fpr)\n",
    "    for i in range(n_class):\n",
    "        mean_tpr += np.interp(all_fpr, fpr[i], tpr[i])\n",
    "        \n",
    "    # Finally average it and compute AUC\n",
    "    mean_tpr = mean_tpr/n_class\n",
    "    fpr[\"macro\"] = all_fpr\n",
    "    tpr[\"macro\"] = mean_tpr\n",
    "    roc_auc[\"macro\"] = auc(fpr[\"macro\"],tpr[\"macro\"])\n",
    "    \n",
    "    return fpr, tpr, roc_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_roc_auc_all(y_test1hot, y_scores):\n",
    "    fprs=dict()\n",
    "    tprs=dict()\n",
    "    roc_aucs=dict()\n",
    "    for key in tqdm(y_scores.keys()):\n",
    "        fprs[key],tprs[key],roc_aucs[key]=compute_roc_auc(y_test1hot,y_scores[key])\n",
    "    \n",
    "    return fprs,tprs,roc_aucs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_roc(fpr, tpr, roc_auc, dataname,modelname,choose = \"all\"):\n",
    "    n_class=4\n",
    "    \n",
    "    # make variable choose as command for choosing which curve to show\n",
    "    # below it's the explaination of choose\n",
    "    ex_choose = {\n",
    "        \"all\": \"show all curves\",\n",
    "        \"macro\": \"only show macro curve\",\n",
    "        \"micro\": \"only show micro curve\",\n",
    "        \"label\": \"only show curves of labels\"\n",
    "        }\n",
    "    \n",
    "    colors = [\"y\", \"g\",\"cornflowerblue\",\"r\"]\n",
    "    label_name = [\"others\", \"happy\",\"sad\",\"angry\"]\n",
    "    plt.figure()\n",
    "    \n",
    "    if (choose !=\"macro\") and (choose !=\"label\"):\n",
    "        # draw the line of micro-average ROC curve\n",
    "        plt.plot(fpr[\"micro\"],tpr[\"micro\"],\n",
    "                 label=\"micro-average ROC (AUC: {0:0.2f})\".format(roc_auc[\"micro\"]),\n",
    "                 color = 'deeppink',linestyle=':',lw=4)\n",
    "    \n",
    "    if (choose !=\"micro\") and (choose !=\"label\"):\n",
    "        # draw the line of macro-average ROC curve\n",
    "        plt.plot(fpr[\"macro\"],tpr[\"macro\"],\n",
    "                 label=\"macro-average ROC (AUC: {0:0.2f})\".format(roc_auc[\"macro\"]),\n",
    "                 color = 'navy',linestyle=':',lw=4)\n",
    "        \n",
    "    if (choose !=\"macro\") and (choose !=\"micro\"):    \n",
    "        # draw line of each label\n",
    "        for i in range(n_class):\n",
    "            plt.plot(fpr[i],tpr[i],color=colors[i],lw=2,\n",
    "                     label=\"ROC of class {0} {1} (AUC: {2:0.2f})\"\n",
    "                     \"\".format(i,label_name[i],roc_auc[i]))\n",
    "    \n",
    "    plt.plot([0,1],[0,1],linestyle=\"--\",color='k',lw=2)\n",
    "    plt.xlim([0.0,1.0])\n",
    "    plt.ylim([0.0,1.1])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('ROC Curve on data {0} by model {1}'.format(dataname,modelname))\n",
    "    \n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.savefig(\"Pictures\\\\{a}\\\\SingleData\\\\ROC Curve by model {b}_{c} on data {d}.png\".format(a=modelname,d=dataname,b=modelname,c=choose))\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fprs,tprs,roc_aucs=compute_roc_auc_all(y_test1hot, y_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelname=\"SVM\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key_name = \"test_baseline\"\n",
    "fpr = fprs[key_name]\n",
    "tpr = tprs[key_name]\n",
    "roc_auc = roc_aucs[key_name]\n",
    "dataname=key_name\n",
    "plot_roc(fpr, tpr, roc_auc, dataname,modelname,choose = \"all\")\n",
    "plot_roc(fpr, tpr, roc_auc, dataname,modelname,choose = \"macro\")\n",
    "plot_roc(fpr, tpr, roc_auc, dataname,modelname,choose = \"micro\")\n",
    "plot_roc(fpr, tpr, roc_auc, dataname,modelname,choose = \"label\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.5. Evaluation: P-R curve, average precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_p_r_curve(y_test1hot, y_score):\n",
    "    n_class = 4\n",
    "    precision = dict()\n",
    "    recall = dict()\n",
    "    average_precision =dict()\n",
    "    \n",
    "    # compute P-R curve on each label\n",
    "    for i in range(n_class):\n",
    "        precision[i],recall[i], _ = precision_recall_curve(y_test1hot[:,i],y_score[:,i])\n",
    "        average_precision[i] = average_precision_score(y_test1hot[:,i],y_score[:,i])\n",
    "        \n",
    "    # compute P-R curve with average = \"micro\"\n",
    "    precision[\"micro\"],recall[\"micro\"],_=precision_recall_curve(y_test1hot.ravel(),y_score.ravel())\n",
    "    average_precision[\"micro\"]=average_precision_score(y_test1hot,y_score,average=\"micro\")\n",
    "    \n",
    "    return precision,recall,average_precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_p_r_curve_all(y_test1hot, y_scores):\n",
    "    recalls=dict()\n",
    "    precisions=dict()\n",
    "    average_precisions=dict()\n",
    "    for key in y_scores.keys():\n",
    "        recalls[key],precisions[key],average_precisions[key]=compute_p_r_curve(y_test1hot,y_scores[key])\n",
    "    \n",
    "    return recalls,precisions,average_precisions\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_pr(recall, precision, average_precision, dataname,modelname,choose = \"all\"):\n",
    "    n_class=4\n",
    "    \n",
    "    # make variable choose as command for choosing which curve to show\n",
    "    # below it's the explaination of choose\n",
    "    ex_choose = {\n",
    "        \"all\": \"show all curves\",\n",
    "        \"micro\": \"only show micro curve\",\n",
    "        \"label\": \"only show curves of labels\"\n",
    "        }\n",
    "    \n",
    "    colors = [\"y\", \"g\",\"cornflowerblue\",\"r\"]\n",
    "    label_name = [\"others\", \"happy\",\"sad\",\"angry\"]\n",
    "    plt.figure()\n",
    "    \n",
    "    if choose !=\"label\":\n",
    "        # draw the line of micro-average ROC curve\n",
    "        plt.plot(recall[\"micro\"],precision[\"micro\"],\n",
    "                 label=\"micro-average P-R curve (average precision: {0:0.2f})\".format(average_precision[\"micro\"]),\n",
    "                 color = 'deeppink',linestyle=':',lw=4)\n",
    "    \n",
    "        \n",
    "    if choose !=\"micro\":    \n",
    "        # draw line of each label\n",
    "        for i in range(n_class):\n",
    "            plt.plot(recall[i],precision[i],color=colors[i],lw=2,\n",
    "                     label=\"P-R curve of class {0} {1} (average precision: {2:0.2f})\"\n",
    "                     \"\".format(i,label_name[i],average_precision[i]))\n",
    "    \n",
    "    plt.plot([0,1],[1,0],linestyle=\"--\",color='k',lw=2)\n",
    "    plt.xlim([0.0,1.0])\n",
    "    plt.ylim([0.0,1.1])\n",
    "    plt.xlabel('Recall')\n",
    "    plt.ylabel('Precision')\n",
    "    plt.title('P-R Curve on data {0} by model {1}'.format(dataname,modelname))\n",
    "    \n",
    "    plt.legend(loc=\"lower left\")\n",
    "    plt.savefig(\"Pictures\\\\{a}\\\\SingleData\\\\P-R Curve by model {b}_{c} on data {d}.png\".format(a=modelname,d=dataname,b=modelname,c=choose))\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recalls,precisions,average_precisions = compute_p_r_curve_all(y_test1hot, y_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key_name=\"test_baseline\"\n",
    "recall=recalls[key_name]\n",
    "precision=precisions[key_name]\n",
    "average_precision=average_precisions[key_name]\n",
    "dataname=key_name\n",
    "plot_pr(recall, precision, average_precision, dataname,modelname,choose = \"all\")\n",
    "plot_pr(recall, precision, average_precision, dataname,modelname,choose = \"micro\")\n",
    "plot_pr(recall, precision, average_precision, dataname,modelname,choose = \"label\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. if just want to directly load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names = {\n",
    "    \"model_all\":\"SVM_baseline\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_data = open_pkl(model_names)\n",
    "classifiers = model_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
